{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD A DATASET WITH ALL FEATURES: PROCEDURE, AFFECTIVE SCORE, EMOTIONS, PERSONALITY ETC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:12:21.694178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 14:12:21.830930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:12:21.830949: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-28 14:12:22.604178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:12:22.604442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 14:12:22.604457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold,cross_val_score,KFold,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Activation,Flatten,MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.utils import normalize, to_categorical\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "path='emo_personality_procedure_df.csv'\n",
    "df_full = pd.read_csv(path,converters={'SEC_EMO': eval,'FIRST_EMO':eval})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUB-NAME</th>\n",
       "      <th>FRAME_NUMBER</th>\n",
       "      <th>IADS_ID</th>\n",
       "      <th>IAPS_ID</th>\n",
       "      <th>ANGER</th>\n",
       "      <th>CONTEMPT</th>\n",
       "      <th>DISGUST</th>\n",
       "      <th>FEAR</th>\n",
       "      <th>HAPPINESS</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>SADNESS</th>\n",
       "      <th>SURPRISE</th>\n",
       "      <th>STIMULI</th>\n",
       "      <th>MEAN_ABS_ERR</th>\n",
       "      <th>MEAN_SQ_ERR</th>\n",
       "      <th>ENERGY</th>\n",
       "      <th>WASSERSTEIN</th>\n",
       "      <th>RELATIVE_ENTROPY</th>\n",
       "      <th>JENSENSHANNON</th>\n",
       "      <th>HELLINGER</th>\n",
       "      <th>BHATTACHARYYA_DIST</th>\n",
       "      <th>CORRELATION</th>\n",
       "      <th>FIRST_EMO</th>\n",
       "      <th>SEC_EMO</th>\n",
       "      <th>COND</th>\n",
       "      <th>ANS_VALENCE</th>\n",
       "      <th>ANS_AROUSAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUB103</td>\n",
       "      <td>300</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.116190</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.281714</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.118494</td>\n",
       "      <td>3.436184e-02</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUB103</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.093554</td>\n",
       "      <td>0.112186</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>2.448778e-04</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUB103</td>\n",
       "      <td>225</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.072298</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>9.750467e-05</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUB103</td>\n",
       "      <td>120</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.022361</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.052732</td>\n",
       "      <td>0.063309</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>3.192657e-05</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUB103</td>\n",
       "      <td>210</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB103_102_None</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>1.791256e-05</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>S0</td>\n",
       "      <td>6.582</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256975</th>\n",
       "      <td>SUB997</td>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.044744</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>3.295350e-06</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS, SADNESS]</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256976</th>\n",
       "      <td>SUB997</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9.863423e-07</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT, HAPPINESS, SADNESS]</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256977</th>\n",
       "      <td>SUB997</td>\n",
       "      <td>225</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>2.137071e-06</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS]</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256978</th>\n",
       "      <td>SUB997</td>\n",
       "      <td>270</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.044734</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>2.137684e-06</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[HAPPINESS]</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256979</th>\n",
       "      <td>SUB997</td>\n",
       "      <td>345</td>\n",
       "      <td>None</td>\n",
       "      <td>9594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SUB997_None_9594</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9.863423e-07</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT, HAPPINESS, SADNESS]</td>\n",
       "      <td>P0</td>\n",
       "      <td>5.052</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256980 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUB-NAME  FRAME_NUMBER IADS_ID IAPS_ID  ANGER  CONTEMPT  DISGUST  FEAR  \\\n",
       "0        SUB103           300     102    None  0.001     0.207      0.0   0.0   \n",
       "1        SUB103           195     102    None  0.000     0.022      0.0   0.0   \n",
       "2        SUB103           225     102    None  0.000     0.001      0.0   0.0   \n",
       "3        SUB103           120     102    None  0.000     0.000      0.0   0.0   \n",
       "4        SUB103           210     102    None  0.000     0.000      0.0   0.0   \n",
       "...         ...           ...     ...     ...    ...       ...      ...   ...   \n",
       "256975   SUB997            45    None    9594  0.000     0.000      0.0   0.0   \n",
       "256976   SUB997           150    None    9594  0.000     0.001      0.0   0.0   \n",
       "256977   SUB997           225    None    9594  0.000     0.001      0.0   0.0   \n",
       "256978   SUB997           270    None    9594  0.000     0.001      0.0   0.0   \n",
       "256979   SUB997           345    None    9594  0.000     0.001      0.0   0.0   \n",
       "\n",
       "        HAPPINESS  NEUTRAL  SADNESS  SURPRISE           STIMULI  MEAN_ABS_ERR  \\\n",
       "0           0.000    0.789    0.003       0.0   SUB103_102_None      0.052750   \n",
       "1           0.000    0.974    0.003       0.0   SUB103_102_None      0.006375   \n",
       "2           0.000    0.985    0.014       0.0   SUB103_102_None      0.003750   \n",
       "3           0.000    0.992    0.008       0.0   SUB103_102_None      0.002000   \n",
       "4           0.000    0.993    0.006       0.0   SUB103_102_None      0.001625   \n",
       "...           ...      ...      ...       ...               ...           ...   \n",
       "256975      0.002    0.996    0.002       0.0  SUB997_None_9594      0.001000   \n",
       "256976      0.001    0.997    0.001       0.0  SUB997_None_9594      0.000750   \n",
       "256977      0.002    0.997    0.000       0.0  SUB997_None_9594      0.000750   \n",
       "256978      0.002    0.997    0.001       0.0  SUB997_None_9594      0.000875   \n",
       "256979      0.001    0.997    0.001       0.0  SUB997_None_9594      0.000750   \n",
       "\n",
       "        MEAN_SQ_ERR    ENERGY  WASSERSTEIN  RELATIVE_ENTROPY  JENSENSHANNON  \\\n",
       "0          0.010922  0.116190     0.052750               inf       0.281714   \n",
       "1          0.000146  0.042205     0.006375               inf       0.093554   \n",
       "2          0.000053  0.031623     0.003750               inf       0.072298   \n",
       "3          0.000016  0.022361     0.002000               inf       0.052732   \n",
       "4          0.000011  0.020156     0.001625               inf       0.045673   \n",
       "...             ...       ...          ...               ...            ...   \n",
       "256975     0.000003  0.019365     0.001000               inf       0.037260   \n",
       "256976     0.000002  0.019365     0.000750               inf       0.032262   \n",
       "256977     0.000002  0.015811     0.000750               inf       0.032262   \n",
       "256978     0.000002  0.020156     0.000875               inf       0.037241   \n",
       "256979     0.000002  0.019365     0.000750               inf       0.032262   \n",
       "\n",
       "        HELLINGER  BHATTACHARYYA_DIST   CORRELATION  FIRST_EMO  \\\n",
       "0        0.334280            0.118494  3.436184e-02  [NEUTRAL]   \n",
       "1        0.112186            0.013172  2.448778e-04  [NEUTRAL]   \n",
       "2        0.086766            0.007557  9.750467e-05  [NEUTRAL]   \n",
       "3        0.063309            0.004016  3.192657e-05  [NEUTRAL]   \n",
       "4        0.054828            0.003512  1.791256e-05  [NEUTRAL]   \n",
       "...           ...                 ...           ...        ...   \n",
       "256975   0.044744            0.002004  3.295350e-06  [NEUTRAL]   \n",
       "256976   0.038744            0.001502  9.863423e-07  [NEUTRAL]   \n",
       "256977   0.038744            0.001502  2.137071e-06  [NEUTRAL]   \n",
       "256978   0.044734            0.001502  2.137684e-06  [NEUTRAL]   \n",
       "256979   0.038744            0.001502  9.863423e-07  [NEUTRAL]   \n",
       "\n",
       "                               SEC_EMO COND  ANS_VALENCE  ANS_AROUSAL  \n",
       "0                           [CONTEMPT]   S0        6.582         5.00  \n",
       "1                           [CONTEMPT]   S0        6.582         5.00  \n",
       "2                            [SADNESS]   S0        6.582         5.00  \n",
       "3                            [SADNESS]   S0        6.582         5.00  \n",
       "4                            [SADNESS]   S0        6.582         5.00  \n",
       "...                                ...  ...          ...          ...  \n",
       "256975            [HAPPINESS, SADNESS]   P0        5.052         6.08  \n",
       "256976  [CONTEMPT, HAPPINESS, SADNESS]   P0        5.052         6.08  \n",
       "256977                     [HAPPINESS]   P0        5.052         6.08  \n",
       "256978                     [HAPPINESS]   P0        5.052         6.08  \n",
       "256979  [CONTEMPT, HAPPINESS, SADNESS]   P0        5.052         6.08  \n",
       "\n",
       "[256980 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop('RELATIVE_ENTROPY',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take only least neutral row from each stimuli\n",
    "#### This is ordered dataset; by stimuli and neutral emotion asc so I can grab it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_only_df=df_full.groupby('STIMULI').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_only_df = first_only_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STIMULI</th>\n",
       "      <th>SUB_NAME</th>\n",
       "      <th>FRAME_NUMBER</th>\n",
       "      <th>IADS_ID</th>\n",
       "      <th>IAPS_ID</th>\n",
       "      <th>ANGER</th>\n",
       "      <th>CONTEMPT</th>\n",
       "      <th>DISGUST</th>\n",
       "      <th>FEAR</th>\n",
       "      <th>HAPPINESS</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>SADNESS</th>\n",
       "      <th>SURPRISE</th>\n",
       "      <th>FIRST_EMO</th>\n",
       "      <th>SEC_EMO</th>\n",
       "      <th>MEAN_ABS_ERR</th>\n",
       "      <th>MEAN_SQ_ERR</th>\n",
       "      <th>ENERGY</th>\n",
       "      <th>WASSERSTEIN</th>\n",
       "      <th>JENSENSHANNON</th>\n",
       "      <th>HELLINGER</th>\n",
       "      <th>BHATTACHARYYA_DIST</th>\n",
       "      <th>CORRELATION</th>\n",
       "      <th>COND</th>\n",
       "      <th>ANS_VALENCE</th>\n",
       "      <th>ANS_AROUSAL</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>NEUROTICISM</th>\n",
       "      <th>AGREEABLENESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SUB465_311_2208</td>\n",
       "      <td>SUB465</td>\n",
       "      <td>210</td>\n",
       "      <td>311</td>\n",
       "      <td>2208</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.055057</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.120161</td>\n",
       "      <td>0.143962</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>PS+</td>\n",
       "      <td>5.022</td>\n",
       "      <td>7.705</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUB457_353_5910</td>\n",
       "      <td>SUB457</td>\n",
       "      <td>90</td>\n",
       "      <td>353</td>\n",
       "      <td>5910</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.061</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.147373</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.321878</td>\n",
       "      <td>0.380697</td>\n",
       "      <td>0.155987</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>PS+</td>\n",
       "      <td>6.194</td>\n",
       "      <td>5.385</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SUB404_None_9426</td>\n",
       "      <td>SUB404</td>\n",
       "      <td>255</td>\n",
       "      <td>None</td>\n",
       "      <td>9426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.050621</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.118605</td>\n",
       "      <td>0.142141</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>P0</td>\n",
       "      <td>2.981</td>\n",
       "      <td>2.518</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SUB318_717_None</td>\n",
       "      <td>SUB318</td>\n",
       "      <td>300</td>\n",
       "      <td>717</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.160080</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.037362</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>S+</td>\n",
       "      <td>5.842</td>\n",
       "      <td>5.311</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SUB170_220_None</td>\n",
       "      <td>SUB170</td>\n",
       "      <td>300</td>\n",
       "      <td>220</td>\n",
       "      <td>None</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.074245</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>S+</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11012</td>\n",
       "      <td>SUB336_None_5621</td>\n",
       "      <td>SUB336</td>\n",
       "      <td>225</td>\n",
       "      <td>None</td>\n",
       "      <td>5621</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[CONTEMPT]</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.158410</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.338099</td>\n",
       "      <td>0.399076</td>\n",
       "      <td>0.174070</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>P+</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11013</td>\n",
       "      <td>SUB348_None_6910</td>\n",
       "      <td>SUB348</td>\n",
       "      <td>270</td>\n",
       "      <td>None</td>\n",
       "      <td>6910</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.051841</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.112435</td>\n",
       "      <td>0.134777</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>P0</td>\n",
       "      <td>2.130</td>\n",
       "      <td>7.733</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11014</td>\n",
       "      <td>SUB920_311_8492</td>\n",
       "      <td>SUB920</td>\n",
       "      <td>195</td>\n",
       "      <td>311</td>\n",
       "      <td>8492</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[ANGER]</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.058095</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.136854</td>\n",
       "      <td>0.163892</td>\n",
       "      <td>0.027228</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>PS+</td>\n",
       "      <td>5.880</td>\n",
       "      <td>6.077</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11015</td>\n",
       "      <td>SUB977_276_3150</td>\n",
       "      <td>SUB977</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>3150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[NEUTRAL]</td>\n",
       "      <td>[SADNESS]</td>\n",
       "      <td>0.050750</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.112916</td>\n",
       "      <td>0.050750</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.327493</td>\n",
       "      <td>0.113450</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>PS-</td>\n",
       "      <td>2.394</td>\n",
       "      <td>7.632</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11016</td>\n",
       "      <td>SUB915_813_7501</td>\n",
       "      <td>SUB915</td>\n",
       "      <td>15</td>\n",
       "      <td>813</td>\n",
       "      <td>7501</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.965</td>\n",
       "      <td>[ANGER]</td>\n",
       "      <td>[HAPPINESS]</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.241531</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.832555</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>14.385228</td>\n",
       "      <td>1.148388</td>\n",
       "      <td>PS+</td>\n",
       "      <td>5.540</td>\n",
       "      <td>4.301</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11017 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STIMULI SUB_NAME  FRAME_NUMBER IADS_ID IAPS_ID  ANGER  \\\n",
       "0       SUB465_311_2208   SUB465           210     311    2208  0.003   \n",
       "1       SUB457_353_5910   SUB457            90     353    5910  0.001   \n",
       "2      SUB404_None_9426   SUB404           255    None    9426  0.000   \n",
       "3       SUB318_717_None   SUB318           300     717    None  0.000   \n",
       "4       SUB170_220_None   SUB170           300     220    None  0.004   \n",
       "...                 ...      ...           ...     ...     ...    ...   \n",
       "11012  SUB336_None_5621   SUB336           225    None    5621  0.000   \n",
       "11013  SUB348_None_6910   SUB348           270    None    6910  0.001   \n",
       "11014   SUB920_311_8492   SUB920           195     311    8492  0.001   \n",
       "11015   SUB977_276_3150   SUB977             0     276    3150  0.000   \n",
       "11016   SUB915_813_7501   SUB915            15     813    7501  0.032   \n",
       "\n",
       "       CONTEMPT  DISGUST   FEAR  HAPPINESS  NEUTRAL  SADNESS  SURPRISE  \\\n",
       "0         0.036      0.0  0.000      0.000    0.958    0.002     0.000   \n",
       "1         0.001      0.0  0.003      0.001    0.732    0.202     0.061   \n",
       "2         0.001      0.0  0.000      0.000    0.960    0.039     0.000   \n",
       "3         0.002      0.0  0.000      0.000    0.928    0.070     0.000   \n",
       "4         0.001      0.0  0.000      0.000    0.990    0.006     0.000   \n",
       "...         ...      ...    ...        ...      ...      ...       ...   \n",
       "11012     0.186      0.0  0.000      0.106    0.706    0.001     0.000   \n",
       "11013     0.005      0.0  0.000      0.000    0.964    0.030     0.000   \n",
       "11014     0.000      0.0  0.000      0.000    0.947    0.000     0.052   \n",
       "11015     0.001      0.0  0.000      0.000    0.797    0.202     0.000   \n",
       "11016     0.000      0.0  0.000      0.001    0.000    0.000     0.965   \n",
       "\n",
       "       FIRST_EMO      SEC_EMO  MEAN_ABS_ERR  MEAN_SQ_ERR    ENERGY  \\\n",
       "0      [NEUTRAL]   [CONTEMPT]      0.010375     0.000384  0.055057   \n",
       "1      [NEUTRAL]    [SADNESS]      0.067125     0.014545  0.147373   \n",
       "2      [NEUTRAL]    [SADNESS]      0.010000     0.000390  0.050621   \n",
       "3      [NEUTRAL]    [SADNESS]      0.018000     0.001261  0.068007   \n",
       "4      [NEUTRAL]    [SADNESS]      0.002625     0.000019  0.032113   \n",
       "...          ...          ...           ...          ...       ...   \n",
       "11012  [NEUTRAL]   [CONTEMPT]      0.073375     0.016534  0.158410   \n",
       "11013  [NEUTRAL]    [SADNESS]      0.009000     0.000278  0.051841   \n",
       "11014  [NEUTRAL]      [ANGER]      0.013250     0.000689  0.058095   \n",
       "11015  [NEUTRAL]    [SADNESS]      0.050750     0.010252  0.112916   \n",
       "11016    [ANGER]  [HAPPINESS]      0.249750     0.241531  0.046771   \n",
       "\n",
       "       WASSERSTEIN  JENSENSHANNON  HELLINGER  BHATTACHARYYA_DIST  CORRELATION  \\\n",
       "0         0.010375       0.120161   0.143962            0.021454     0.000673   \n",
       "1         0.067125       0.321878   0.380697            0.155987     0.038307   \n",
       "2         0.010000       0.118605   0.142141            0.020411     0.000811   \n",
       "3         0.018000       0.160080   0.191500            0.037362     0.002813   \n",
       "4         0.002625       0.061836   0.074245            0.005025     0.000021   \n",
       "...            ...            ...        ...                 ...          ...   \n",
       "11012     0.073375       0.338099   0.399076            0.174070     0.040843   \n",
       "11013     0.009000       0.112435   0.134777            0.018332     0.000460   \n",
       "11014     0.013250       0.136854   0.163892            0.027228     0.001488   \n",
       "11015     0.050750       0.275862   0.327493            0.113450     0.032204   \n",
       "11016     0.008500       0.832555   0.999500           14.385228     1.148388   \n",
       "\n",
       "      COND  ANS_VALENCE  ANS_AROUSAL  OPENNESS  CONSCIENTIOUSNESS  \\\n",
       "0      PS+        5.022        7.705         7                  5   \n",
       "1      PS+        6.194        5.385         3                  4   \n",
       "2       P0        2.981        2.518         9                  7   \n",
       "3       S+        5.842        5.311         5                  6   \n",
       "4       S+        9.000        1.000         6                  3   \n",
       "...    ...          ...          ...       ...                ...   \n",
       "11012   P+        9.000        9.000         7                  1   \n",
       "11013   P0        2.130        7.733         8                  4   \n",
       "11014  PS+        5.880        6.077         3                 10   \n",
       "11015  PS-        2.394        7.632         6                  7   \n",
       "11016  PS+        5.540        4.301         6                  5   \n",
       "\n",
       "       NEUROTICISM  AGREEABLENESS  EXTRAVERSION  \n",
       "0                5              3             6  \n",
       "1                5              5             5  \n",
       "2                4             10             9  \n",
       "3                4              5             5  \n",
       "4                3              3             7  \n",
       "...            ...            ...           ...  \n",
       "11012           10              9             7  \n",
       "11013           10              4             4  \n",
       "11014            5              7             7  \n",
       "11015            2              7             8  \n",
       "11016            5              3             4  \n",
       "\n",
       "[11017 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input and output for model testing\n",
    "\n",
    "Input to be tested:\n",
    "\n",
    "    1.emotion distribution only\n",
    "    2.emotion distribution + personality traits\n",
    "    3.chosen statistical distances + categorical data of first and second most recognized emotion + personality traits\n",
    "   \n",
    "Output to be tested (val/arousal):\n",
    "\n",
    "    1.continous --> regression problem\n",
    "    2.categorical --> classification problem: LOW,MODERATE,HIGH VxA (VALUES ARE 1-9 ORGINALLY)\n",
    "                                              or LOW,HIGH VxA\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_only_df=first_only_df[['ANGER','CONTEMPT','DISGUST','FEAR','HAPPINESS','NEUTRAL','SADNESS','SURPRISE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_personality_df=first_only_df[['ANGER','CONTEMPT','DISGUST','FEAR','HAPPINESS','NEUTRAL','SADNESS','SURPRISE','OPENNESS','CONSCIENTIOUSNESS','NEUROTICISM','AGREEABLENESS','EXTRAVERSION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chosen stat distances: \n",
    "we could choose the useful ones based on its st dev and mean. the more deviation the more \"active\" the measure is and perhaps can yield best results\n",
    "also it would be good to exclude correlation effects between those we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_ABS_ERR std:  0.05871694138854942   mean:  0.04725452709449026\n",
      "MEAN_SQ_ERR std:  0.049869753702819694   mean:  0.021872283890805165\n",
      "ENERGY std:  0.04804134057357719   mean:  0.08339113610596846\n",
      "WASSERSTEIN std:  0.03412057343278708   mean:  0.034281916583461795\n",
      "JENSENSHANNON std:  0.17960019611312467   mean:  0.23329942360722494\n",
      "HELLINGER std:  0.20814392916338742   mean:  0.27519487965268064\n",
      "BHATTACHARYYA_DIST std:  0.7715897503421418   mean:  0.19184335772446046\n",
      "CORRELATION std:  0.25794473605979784   mean:  0.10717916406908862\n"
     ]
    }
   ],
   "source": [
    "distances_lst=['MEAN_ABS_ERR','MEAN_SQ_ERR','ENERGY','WASSERSTEIN','JENSENSHANNON','HELLINGER','BHATTACHARYYA_DIST','CORRELATION']\n",
    "#distances_lst=['MEAN_ABS_ERR']\n",
    "for dist in distances_lst:\n",
    "    dist_df=first_only_df[dist]\n",
    "    print(dist, 'std: ',dist_df.std(),'  mean: ',dist_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson corr btween  MEAN_ABS_ERR and  MEAN_ABS_ERR is:  1.0\n",
      "pearson corr btween  MEAN_ABS_ERR and  MEAN_SQ_ERR is:  0.9382144692559542\n",
      "pearson corr btween  MEAN_ABS_ERR and  ENERGY is:  0.5456154538048086\n",
      "pearson corr btween  MEAN_ABS_ERR and  WASSERSTEIN is:  0.5848687965958045\n",
      "pearson corr btween  MEAN_ABS_ERR and  JENSENSHANNON is:  0.9873156461250121\n",
      "pearson corr btween  MEAN_ABS_ERR and  HELLINGER is:  0.9850048792383168\n",
      "pearson corr btween  MEAN_ABS_ERR and  BHATTACHARYYA_DIST is:  0.525545936223407\n",
      "pearson corr btween  MEAN_ABS_ERR and  CORRELATION is:  0.9379683098335647\n",
      "##############\n",
      "pearson corr btween  MEAN_SQ_ERR and  MEAN_ABS_ERR is:  0.9382144692559542\n",
      "pearson corr btween  MEAN_SQ_ERR and  MEAN_SQ_ERR is:  0.9999999999999999\n",
      "pearson corr btween  MEAN_SQ_ERR and  ENERGY is:  0.2264755564978134\n",
      "pearson corr btween  MEAN_SQ_ERR and  WASSERSTEIN is:  0.2771717395465841\n",
      "pearson corr btween  MEAN_SQ_ERR and  JENSENSHANNON is:  0.8923657908319992\n",
      "pearson corr btween  MEAN_SQ_ERR and  HELLINGER is:  0.8894294222982129\n",
      "pearson corr btween  MEAN_SQ_ERR and  BHATTACHARYYA_DIST is:  0.580444079836994\n",
      "pearson corr btween  MEAN_SQ_ERR and  CORRELATION is:  0.9909787097024937\n",
      "##############\n",
      "pearson corr btween  ENERGY and  MEAN_ABS_ERR is:  0.5456154538048087\n",
      "pearson corr btween  ENERGY and  MEAN_SQ_ERR is:  0.2264755564978134\n",
      "pearson corr btween  ENERGY and  ENERGY is:  0.9999999999999999\n",
      "pearson corr btween  ENERGY and  WASSERSTEIN is:  0.9643390696854344\n",
      "pearson corr btween  ENERGY and  JENSENSHANNON is:  0.6250521519591351\n",
      "pearson corr btween  ENERGY and  HELLINGER is:  0.6251636389257781\n",
      "pearson corr btween  ENERGY and  BHATTACHARYYA_DIST is:  0.08345205849698123\n",
      "pearson corr btween  ENERGY and  CORRELATION is:  0.2509657566688536\n",
      "##############\n",
      "pearson corr btween  WASSERSTEIN and  MEAN_ABS_ERR is:  0.5848687965958044\n",
      "pearson corr btween  WASSERSTEIN and  MEAN_SQ_ERR is:  0.27717173954658403\n",
      "pearson corr btween  WASSERSTEIN and  ENERGY is:  0.9643390696854345\n",
      "pearson corr btween  WASSERSTEIN and  WASSERSTEIN is:  1.0\n",
      "pearson corr btween  WASSERSTEIN and  JENSENSHANNON is:  0.6386932749530684\n",
      "pearson corr btween  WASSERSTEIN and  HELLINGER is:  0.6381897780839507\n",
      "pearson corr btween  WASSERSTEIN and  BHATTACHARYYA_DIST is:  0.10130601176968311\n",
      "pearson corr btween  WASSERSTEIN and  CORRELATION is:  0.3023466722540416\n",
      "##############\n",
      "pearson corr btween  JENSENSHANNON and  MEAN_ABS_ERR is:  0.9873156461250122\n",
      "pearson corr btween  JENSENSHANNON and  MEAN_SQ_ERR is:  0.8923657908319993\n",
      "pearson corr btween  JENSENSHANNON and  ENERGY is:  0.625052151959135\n",
      "pearson corr btween  JENSENSHANNON and  WASSERSTEIN is:  0.6386932749530684\n",
      "pearson corr btween  JENSENSHANNON and  JENSENSHANNON is:  1.0\n",
      "pearson corr btween  JENSENSHANNON and  HELLINGER is:  0.9997373929062489\n",
      "pearson corr btween  JENSENSHANNON and  BHATTACHARYYA_DIST is:  0.5055348018131195\n",
      "pearson corr btween  JENSENSHANNON and  CORRELATION is:  0.8856020081929892\n",
      "##############\n",
      "pearson corr btween  HELLINGER and  MEAN_ABS_ERR is:  0.9850048792383168\n",
      "pearson corr btween  HELLINGER and  MEAN_SQ_ERR is:  0.8894294222982129\n",
      "pearson corr btween  HELLINGER and  ENERGY is:  0.625163638925778\n",
      "pearson corr btween  HELLINGER and  WASSERSTEIN is:  0.6381897780839507\n",
      "pearson corr btween  HELLINGER and  JENSENSHANNON is:  0.9997373929062487\n",
      "pearson corr btween  HELLINGER and  HELLINGER is:  0.9999999999999999\n",
      "pearson corr btween  HELLINGER and  BHATTACHARYYA_DIST is:  0.5094028719607145\n",
      "pearson corr btween  HELLINGER and  CORRELATION is:  0.8808419799193514\n",
      "##############\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  MEAN_ABS_ERR is:  0.525545936223407\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  MEAN_SQ_ERR is:  0.580444079836994\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  ENERGY is:  0.08345205849698123\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  WASSERSTEIN is:  0.10130601176968312\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  JENSENSHANNON is:  0.5055348018131195\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  HELLINGER is:  0.5094028719607147\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  BHATTACHARYYA_DIST is:  0.9999999999999999\n",
      "pearson corr btween  BHATTACHARYYA_DIST and  CORRELATION is:  0.5723333014123434\n",
      "##############\n",
      "pearson corr btween  CORRELATION and  MEAN_ABS_ERR is:  0.9379683098335647\n",
      "pearson corr btween  CORRELATION and  MEAN_SQ_ERR is:  0.9909787097024938\n",
      "pearson corr btween  CORRELATION and  ENERGY is:  0.2509657566688537\n",
      "pearson corr btween  CORRELATION and  WASSERSTEIN is:  0.3023466722540416\n",
      "pearson corr btween  CORRELATION and  JENSENSHANNON is:  0.8856020081929893\n",
      "pearson corr btween  CORRELATION and  HELLINGER is:  0.8808419799193514\n",
      "pearson corr btween  CORRELATION and  BHATTACHARYYA_DIST is:  0.5723333014123434\n",
      "pearson corr btween  CORRELATION and  CORRELATION is:  1.0\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "#first_only_df['BHATTACHARYYA_DIST'].corr(first_only_df['HELLINGER'])\n",
    "for dist_1 in distances_lst:\n",
    "    dist_1_df=first_only_df[dist_1]\n",
    "    for dist_2 in distances_lst:\n",
    "        dist_2_df=first_only_df[dist_2]\n",
    "        print('pearson corr btween ', dist_1,'and ', dist_2, 'is: ', dist_1_df.corr(dist_2_df))\n",
    "    print('##############')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will go with BHATTACHARYYA_DIST and HELLINGER: 0.5 correlation (moderate) and and highest std  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=first_only_df[['BHATTACHARYYA_DIST','HELLINGER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hot-one encode first and second highest recognized emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "hot_one_f=pd.DataFrame(mlb.fit_transform(first_only_df.FIRST_EMO),columns=mlb.classes_, index=first_only_df.index)\n",
    "hot_one_s=pd.DataFrame(mlb.fit_transform(first_only_df.SEC_EMO),columns=mlb.classes_, index=first_only_df.index)\n",
    "\n",
    "hot_one_f.rename({    \n",
    "    'ANGER':'ANGER_F',\n",
    "    'CONTEMPT':'CONTEMPT_F',\n",
    "    'DISGUST':'DISGUST_F',\n",
    "    'FEAR':'FEAR_F',\n",
    "    'HAPPINESS':'HAPPINESS_F',\n",
    "    'NEUTRAL':'NEUTRAL_F',\n",
    "    'SADNESS':'SADNESS_F',    \n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "hot_one_s.rename({    \n",
    "    'ANGER':'ANGER_S',\n",
    "    'CONTEMPT':'CONTEMPT_S',\n",
    "    'DISGUST':'DISGUST_S',\n",
    "    'FEAR':'FEAR_S',\n",
    "    'HAPPINESS':'HAPPINESS_S',\n",
    "    'NEUTRAL':'NEUTRAL_S',\n",
    "    'SADNESS':'SADNESS_S',    \n",
    "    }, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "hot_one_both=pd.merge(hot_one_f, hot_one_s, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_df=first_only_df[['OPENNESS','CONSCIENTIOUSNESS','NEUROTICISM','AGREEABLENESS','EXTRAVERSION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cat_pers_df=pd.merge(dist_df, hot_one_both, left_index=True, right_index=True)\n",
    "stat_cat_pers_df=pd.merge(stat_cat_pers_df, personality_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=first_only_df[['ANS_VALENCE','ANS_AROUSAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat(val):\n",
    "    if val >=1 and val <3:\n",
    "        return 'LOW'\n",
    "    elif val >=3 and val <6:\n",
    "        return 'MODERATE'\n",
    "    elif val >=6 and val <=9:\n",
    "        return 'HIGH'\n",
    "def to_cat2(val):\n",
    "    if val >=1 and val <5:\n",
    "        return 'LOW'\n",
    "    elif val >=5 and val <=9:\n",
    "        return 'HIGH'\n",
    "    \n",
    "def to_num(key):\n",
    "    classes={\n",
    "    'LOW VALENCE LOW AROUSAL':0,\n",
    "    'LOW VALENCE MODERATE AROUSAL':1,\n",
    "    'LOW VALENCE HIGH AROUSAL':2,\n",
    "    'MODERATE VALENCE LOW AROUSAL':3,\n",
    "    'MODERATE VALENCE MODERATE AROUSAL':4,\n",
    "    'MODERATE VALENCE HIGH AROUSAL':5,\n",
    "    'HIGH VALENCE LOW AROUSAL':6,\n",
    "    'HIGH VALENCE MODERATE AROUSAL':7,\n",
    "    'HIGH VALENCE HIGH AROUSAL':8,\n",
    "    }\n",
    "    return classes.get(key)\n",
    "\n",
    "def to_num2(key):\n",
    "    classes={\n",
    "    'LOW VALENCE LOW AROUSAL':0,\n",
    "    'LOW VALENCE HIGH AROUSAL':1,\n",
    "    'HIGH VALENCE LOW AROUSAL':2,\n",
    "    'HIGH VALENCE HIGH AROUSAL':3,\n",
    "    }\n",
    "    return classes.get(key)\n",
    "\n",
    "y_df['AROUSAL_VAL_CAT'] = y_df.apply(lambda row: to_cat(row['ANS_VALENCE']) +' VALENCE '+ to_cat(row['ANS_AROUSAL']) + ' AROUSAL' , axis=1)\n",
    "y_df['VAL_AR_NUM']=y_df.apply(lambda row: to_num(row['AROUSAL_VAL_CAT']), axis=1)\n",
    "\n",
    "y_df['AROUSAL_VAL_CAT2'] = y_df.apply(lambda row: to_cat2(row['ANS_VALENCE']) +' VALENCE '+ to_cat2(row['ANS_AROUSAL']) + ' AROUSAL' , axis=1)\n",
    "y_df['VAL_AR_NUM2']=y_df.apply(lambda row: to_num2(row['AROUSAL_VAL_CAT2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "    \n",
    "    \n",
    "y=y_df[['ANS_VALENCE','ANS_AROUSAL']].to_numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.022, 7.705],\n",
       "       [6.194, 5.385],\n",
       "       [2.981, 2.518],\n",
       "       ...,\n",
       "       [5.88 , 6.077],\n",
       "       [2.394, 7.632],\n",
       "       [5.54 , 4.301]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=[5,10,15,20,30,40,50]\n",
    "activations_last_layer=['linear','relu']\n",
    "epochs=[20,40]\n",
    "y=y_df[['ANS_VALENCE','ANS_AROUSAL']].to_numpy()\n",
    "\n",
    "def NN_regression(n_inputs, n_outputs,unit,activation):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(unit, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs,activation=activation))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "with open('ModelsResults.txt', 'w') as file:\n",
    "            file.write('Regression Approach:\\nNEURAL NETWORK- 2 dense layers (input and output)'.format(input_[1]))\n",
    "\n",
    "for input_ in input_lst_transform:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "    with open('ModelsResults.txt', 'a') as file:\n",
    "                file.write('\\n Input used: {}'.format(input_[1]))\n",
    "    for unit in units:\n",
    "        for activation in activations_last_layer:\n",
    "            for epoch_n in epochs:\n",
    "                model=NN_regression(X_train.shape[1], y_train.shape[1],unit,activation)\n",
    "                history = model.fit(X_train, y_train, validation_split=0.2, epochs =epoch_n,verbose=0)\n",
    "                mse_neural, mae_neural = model.evaluate(X_test, y_test)\n",
    "                with open('ModelsResults.txt', 'a') as file:\n",
    "                    file.write(\"\"\"\\n\\n\\t Configuration: {} units, {} activation function on output layer, {} epochs\n",
    "                                   \\n\\t\\t Mean squared error from neural net: {}\n",
    "                                   \\n\\t\\t Mean absolute error from neural net: {}\"\"\".format(unit,activation,\n",
    "                                                                                            epoch_n,mse_neural,mae_neural))\n",
    "#     print('Mean squared error from neural net: ', mse_neural)\n",
    "#     print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['mae']\n",
    "# val_acc = history.history['val_mae']\n",
    "# plt.plot(epochs, acc, 'y', label='Training MAE')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation MAE')\n",
    "# plt.title('Training and validation MAE')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('MAE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: \n",
    "# predictions = model.predict(X_test[15:20:])\n",
    "# print(\"Predicted values are:\\n\\n\", predictions)\n",
    "# print(\"\\nReal values are:\\n\\n\", y_test[15:20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random  Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find good parameters by randomly choosing combination of parameters. Save the best ones and write an estimation to txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "best_random_lst=[]\n",
    "for input_ in input_lst_transform:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, \n",
    "                                   verbose=1, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    res=(input_[1],rf_random.best_estimator_)\n",
    "    best_random_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RandomForestRegression.txt', 'w') as file:\n",
    "    file.write(\"RandomForestRegression\")\n",
    "\n",
    "\n",
    "for name, model in best_random_lst:\n",
    "    with open('RandomForestRegression.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name,model))\n",
    "    \n",
    "    for data,ds_name in input_lst_transform:\n",
    "        if ds_name == name:\n",
    "            X = data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_RF = model.predict(X_test)\n",
    "    mse_RF = mean_squared_error(y_test, y_pred_RF)\n",
    "    mae_RF = mean_absolute_error(y_test, y_pred_RF)\n",
    "    with open('RandomForestRegression.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Mean squared error using Random Forest: {}'\\n\\t'Mean absolute error using Random Forest: {}\".format(mse_RF,mae_RF))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = MultiOutputRegressor(SVR())\n",
    "xd.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out how different kernels and C, gamma values affect the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "param_grid = {'estimator__C': [0.1, 1, 10, 100, 1000], \n",
    "              'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'estimator__kernel': ['linear','rbf','sigmoid']} \n",
    "\n",
    "best_estimator_lst = []\n",
    "for input_ in input_lst_transform:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_[0], y, test_size = 0.2, random_state = 42)\n",
    "    grid = GridSearchCV(MultiOutputRegressor(SVR()), param_grid, cv=5, verbose = 3,n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    res=(input_[1],grid.best_estimator_)\n",
    "    best_estimator_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SupportVectorRegression.txt', 'w') as file:\n",
    "    file.write(\"SupportVectorRegression\")\n",
    "\n",
    "\n",
    "for name, model in best_estimator_lst:\n",
    "    with open('SupportVectorRegression.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name,model))\n",
    "    \n",
    "    for data,ds_name in input_lst_transform:\n",
    "        if ds_name == name:\n",
    "            X = data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_SVR = model.predict(X_test)\n",
    "    mse_SVR = mean_squared_error(y_test, y_pred_SVR)\n",
    "    mae_SVR = mean_absolute_error(y_test, y_pred_SVR)\n",
    "    with open('SupportVectorRegression.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Mean squared error using SVR: {}'\\n\\t'Mean absolute error using SVR: {}\".format(mse_SVR,mae_SVR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 CATEGORIES\n",
      "AROUSAL_VAL_CAT\n",
      "LOW VALENCE LOW AROUSAL               289\n",
      "HIGH VALENCE LOW AROUSAL              372\n",
      "MODERATE VALENCE LOW AROUSAL          694\n",
      "MODERATE VALENCE HIGH AROUSAL        1064\n",
      "LOW VALENCE MODERATE AROUSAL         1189\n",
      "HIGH VALENCE HIGH AROUSAL            1475\n",
      "HIGH VALENCE MODERATE AROUSAL        1600\n",
      "LOW VALENCE HIGH AROUSAL             2005\n",
      "MODERATE VALENCE MODERATE AROUSAL    2329\n",
      "dtype: int64\n",
      "\n",
      "4 CATEGORIES\n",
      "AROUSAL_VAL_CAT2\n",
      "LOW VALENCE LOW AROUSAL      1604\n",
      "HIGH VALENCE LOW AROUSAL     1789\n",
      "HIGH VALENCE HIGH AROUSAL    3550\n",
      "LOW VALENCE HIGH AROUSAL     4074\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_ar_size=y_df.groupby(by='AROUSAL_VAL_CAT').size().sort_values()\n",
    "print('9 CATEGORIES')\n",
    "print(val_ar_size)\n",
    "print()\n",
    "val_ar_size2=y_df.groupby(by='AROUSAL_VAL_CAT2').size().sort_values()\n",
    "print('4 CATEGORIES')\n",
    "print(val_ar_size2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20d84997908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_ar_size.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20d84f53648>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_ar_size2.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "\n",
    "output_lst=[\n",
    "    (y_df[['VAL_AR_NUM']].to_numpy(),'9 Categories'),\n",
    "    (y_df[['VAL_AR_NUM2']].to_numpy(),'4 Categories')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=[5,10,15,20,30,40,50]\n",
    "epochs=[20,40]\n",
    "\n",
    "\n",
    "def NN_classifier(n_inputs, n_outputs,unit):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(unit, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "with open('NeuralNetClassifier.txt', 'w') as file:\n",
    "            file.write('Classification Approach:\\nNEURAL NETWORK- 2 dense layers (input and output)')\n",
    "\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        y=to_categorical(output)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, y, test_size = 0.2, random_state = 42)\n",
    "        with open('NeuralNetClassifier.txt', 'a') as file:\n",
    "                    file.write('\\n Input used: {},\\noutput used: {}'.format(name_i,name_o))\n",
    "        for unit in units:\n",
    "            for epoch_n in epochs:\n",
    "                model=NN_classifier(X_train.shape[1], y_train.shape[1],unit)\n",
    "                history = model.fit(X_train, y_train, validation_split=0.2, epochs =epoch_n,verbose=0)\n",
    "                loss_neural, acc_neural = model.evaluate(X_test, y_test)\n",
    "                with open('NeuralNetClassifier.txt', 'a') as file:\n",
    "                    file.write(\"\"\"\\n\\n\\t Configuration: {} units, {} epochs\n",
    "                                   \\n\\t\\t Loss: {}\\n\\t\\t Accuracy: {}\"\"\".format(unit,epoch_n,loss_neural,acc_neural))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "best_random_lst=[]\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        output=to_categorical(output)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, \n",
    "                                       verbose=1, random_state=42, n_jobs = -1)\n",
    "        rf_random.fit(X_train, y_train)\n",
    "        res=(name_i,name_o,rf_random.best_estimator_)\n",
    "        best_random_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RandomForestClassification.txt', 'w') as file:\n",
    "    file.write(\"RandomForestClassification\")\n",
    "\n",
    "\n",
    "for name_in_best,name_out_best, model in best_random_lst:\n",
    "    for data_in,ds_name_in in input_lst_transform:\n",
    "        if ds_name_in == name_in_best:\n",
    "            X = data_in\n",
    "\n",
    "    for data_out,ds_name_out in output_lst:\n",
    "        if ds_name_out == name_out_best:\n",
    "            y = data_out\n",
    "\n",
    "    y=to_categorical(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    with open('RandomForestClassification.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}\\noutput data used: {}\\nmodel parameters used: {}\\n\\n\".format(name_in_best,name_out_best,model))\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_RF = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred_RF)\n",
    "    with open('RandomForestClassification.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\t'Accuracy using Random Forest: {}\".format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "#Setting C: C is 1 by default and it’s a reasonable default choice. If you have a lot of noisy observations you should decrease it:\n",
    "# it takes forever for 'linear' kernel+big values of C so not going to try it \n",
    "#One is advised to use GridSearchCV with C and gamma spaced exponentially far apart to choose good values.\n",
    "param_grid = {'C': [0.001,0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001,'scale','auto'],\n",
    "              'kernel': ['rbf','sigmoid'],\n",
    "              'class_weight':['balanced',None]} \n",
    "\n",
    "best_estimator_lst = []\n",
    "for input_,name_i in input_lst_transform:\n",
    "    for output,name_o in output_lst:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_, output.ravel(), test_size = 0.2, random_state = 42)\n",
    "        grid = GridSearchCV((SVC()), param_grid, cv=5, verbose = 3,n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        res=(name_i,name_o,grid.best_estimator_)\n",
    "        best_estimator_lst.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SupportVectorClassification.txt', 'w') as file:\n",
    "    file.write(\"SupportVectorClassification\")\n",
    "\n",
    "\n",
    "for name_in_best,name_out_best, model in best_estimator_lst:\n",
    "    for data_in,ds_name_in in input_lst_transform:\n",
    "        if ds_name_in == name_in_best:\n",
    "            X = data_in\n",
    "    for data_out,ds_name_out in output_lst:\n",
    "        if ds_name_out == name_out_best:\n",
    "            y = data_out       \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size = 0.2, random_state = 42)\n",
    "    with open('SupportVectorClassification.txt', 'a') as file:\n",
    "        file.write(\"\\n\\nInput data used: {}Output data used: {}\\nmodel parameters used: {}\\n\\n\".format(name_in_best,name_out_best,model))\n",
    "           \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_SVM = model.predict(X_test)\n",
    "    acc=accuracy_score(y_test, y_pred_SVM)\n",
    "    with open('SupportVectorClassification.txt', 'a') as file:\n",
    "        file.write(\"Results\\n\\tAccuracy using SVM: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[\n",
    "    (emo_only_df,'emotion only'),\n",
    "    (emo_personality_df, 'emotion + personality'),\n",
    "    (stat_cat_pers_df, 'stat distanes + emotion labels')\n",
    "]\n",
    "\n",
    "input_lst_transform=[]\n",
    "for X,name in input_lst:\n",
    "    X=X.to_numpy()\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    res=(X,name)\n",
    "    input_lst_transform.append(res)\n",
    "\n",
    "output_lst=[\n",
    "    (y_df[['VAL_AR_NUM']].to_numpy(),'9 Categories'),\n",
    "    (y_df[['VAL_AR_NUM2']].to_numpy(),'4 Categories')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_lst_transform[1][0], output_lst[1][0].ravel(), test_size = 0.2, random_state = 42)\n",
    "\n",
    "sv=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n",
    "sv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y= np.full((2204, 1), 1, dtype=int)\n",
    "\n",
    "y_pred_SVM = sv.predict(X_test)\n",
    "acc=accuracy_score(y_test, dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3938294010889292"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
